import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import joblib
import os
from datetime import datetime, timedelta
from neuralforecast import NeuralForecast
import plotly.graph_objects as go
import plotly.express as px

# Thi·∫øt l·∫≠p trang
st.set_page_config(
    page_title="D·ª± b√°o s·∫£n l∆∞·ª£ng ƒëi·ªán & ph√°t hi·ªán b·∫•t th∆∞·ªùng",
    page_icon="‚ö°",
    layout="wide",
    initial_sidebar_state="expanded",
)

# T√πy ch·ªânh CSS
st.markdown("""
    <style>
    .block-container {
        padding-top: 1rem;
        padding-bottom: 1rem;
    }
    .css-1v0mbdj {
        margin-top: -60px;
    }
    .st-emotion-cache-16txtl3 h1 {
        font-weight: 700;
        color: #1E3A8A;
    }
    .sidebar .sidebar-content {
        background-color: #f8f9fa;
    }
    .css-1v3fvcr {
        background-color: #f8f9fa;
    }
    .stButton>button {
        background-color: #1E3A8A;
        color: white;
        border-radius: 4px;
        padding: 0.5rem 1rem;
        font-weight: 600;
    }
    .stButton>button:hover {
        background-color: #1e40af;
    }
    .metric-card {
        background-color: white;
        border-radius: 5px;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        padding: 1rem;
        text-align: center;
    }
    .metric-value {
        font-size: 2rem;
        font-weight: 700;
        color: #1E3A8A;
        margin-bottom: 0;
    }
    .metric-label {
        font-size: 1rem;
        color: #6B7280;
        margin-top: 0;
    }
    .anomaly-high {
        background-color: #FEE2E2;
        color: #B91C1C;
        padding: 0.25rem 0.5rem;
        border-radius: 9999px;
        font-weight: 600;
    }
    .anomaly-normal {
        background-color: #ECFDF5;
        color: #047857;
        padding: 0.25rem 0.5rem;
        border-radius: 9999px;
        font-weight: 600;
    }
    </style>
    """, unsafe_allow_html=True)


# --------- FUNCTIONS ----------

@st.cache_resource
def load_model_and_scalers(model_path, scalers_path):
    """T·∫£i m√¥ h√¨nh v√† scalers (c√≥ cache)"""
    try:
        # Load m√¥ h√¨nh
        model = NeuralForecast.load(model_path)
        
        # Load scalers
        scalers = joblib.load(scalers_path)
        
        return model, scalers
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i m√¥ h√¨nh v√† scalers: {e}")
        st.stop()

@st.cache_data
def load_data(csv_path):
    """T·∫£i d·ªØ li·ªáu ban ƒë·∫ßu (c√≥ cache)"""
    try:
        df = pd.read_csv(csv_path, parse_dates=['NGAYGIO_rounded'])
        df = df.rename(columns={
            'SO_CTO': 'unique_id',
            'NGAYGIO_rounded': 'ds',
            'tv delta': 'y'
        })
        df = df.sort_values(['unique_id', 'ds']).reset_index(drop=True)
        return df
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i d·ªØ li·ªáu: {e}")
        st.stop()

def get_unique_ids(df):
    """L·∫•y danh s√°ch unique_id t·ª´ DataFrame"""
    return sorted(df['unique_id'].unique())

def prepare_data_for_prediction(df, unique_id):
    """Chu·∫©n b·ªã d·ªØ li·ªáu cho m·ªôt ID c·ª• th·ªÉ"""
    data = df[df['unique_id'] == unique_id].copy()
    
    if len(data) < 10:  # Ki·ªÉm tra xem c√≥ ƒë·ªß d·ªØ li·ªáu kh√¥ng
        st.warning(f"Kh√¥ng ƒë·ªß d·ªØ li·ªáu cho c√¥ng t∆° {unique_id}")
        return None
        
    return data

def scale_data(data, scalers, unique_id):
    """Chu·∫©n h√≥a d·ªØ li·ªáu v·ªõi scalers ƒë√£ l∆∞u"""
    try:
        if unique_id in scalers:
            scaler = scalers[unique_id]
            data_copy = data.copy()
            data_copy['y'] = scaler.transform(data_copy[['y']])
            return data_copy, scaler
        else:
            st.warning(f"Kh√¥ng t√¨m th·∫•y scaler cho ID: {unique_id}")
            return None, None
    except Exception as e:
        st.error(f"L·ªói khi chu·∫©n h√≥a d·ªØ li·ªáu: {e}")
        return None, None

def make_forecast(model, data, forecast_len):
    """Th·ª±c hi·ªán d·ª± b√°o"""
    try:
        # ƒê·∫£m b·∫£o r·∫±ng d·ªØ li·ªáu ƒë·∫ßu v√†o c√≥ ƒë√∫ng ƒë·ªãnh d·∫°ng
        train_data = data[['unique_id', 'ds', 'y']].copy()
        
        # D·ª± b√°o
        forecast_df = model.predict(df=train_data)
        return forecast_df
    except Exception as e:
        st.error(f"L·ªói khi d·ª± b√°o: {e}")
        return None

def generate_future_dates(last_date, num_days):
    """T·∫°o c√°c ng√†y gi·ªù t∆∞∆°ng lai ƒë·ªÉ d·ª± b√°o v·ªõi c√°c m·ªëc th·ªùi gian 00, 06, 12, 18"""
    future_dates = []
    
    # ƒê·∫£m b·∫£o last_date ƒë∆∞·ª£c chu·∫©n h√≥a v·ªÅ m√∫i gi·ªù UTC
    if last_date.tzinfo is not None:
        last_date = last_date.replace(tzinfo=None)
    
    # T√¨m m·ªëc th·ªùi gian ti·∫øp theo (00, 06, 12, 18)
    current_hour = last_date.hour
    next_time_slot = (current_hour // 6 + 1) * 6
    if next_time_slot == 24:
        # Chuy·ªÉn sang ng√†y h√¥m sau ·ªü m√∫i gi·ªù 00
        start_date = (last_date + timedelta(days=1)).replace(hour=0, minute=0, second=0, microsecond=0)
    else:
        # Chuy·ªÉn sang m·ªëc gi·ªù ti·∫øp theo trong ng√†y
        start_date = last_date.replace(hour=next_time_slot, minute=0, second=0, microsecond=0)
    
    # T·∫°o c√°c m·ªëc th·ªùi gian cho s·ªë ng√†y c·∫ßn d·ª± b√°o
    for day in range(num_days):
        for hour in [0, 6, 12, 18]:
            # T√≠nh to√°n ng√†y v√† gi·ªù cho m·ªói ƒëi·ªÉm d·ª± b√°o
            forecast_date = start_date + timedelta(days=day)
            forecast_date = forecast_date.replace(hour=hour)
            future_dates.append(forecast_date)
    
    # Lo·∫°i b·ªè c√°c m·ªëc th·ªùi gian ƒë√£ qua so v·ªõi start_date
    future_dates = [date for date in future_dates if date >= start_date]
    
    # Ch·ªâ l·∫•y ƒë√∫ng s·ªë ƒëi·ªÉm c·∫ßn thi·∫øt (4 ƒëi·ªÉm/ng√†y * s·ªë ng√†y)
    return future_dates[:num_days * 4]

def prepare_future_data(data, unique_id, num_days, start_date=None, start_hour=0):
    """Chu·∫©n b·ªã d·ªØ li·ªáu cho d·ª± b√°o t∆∞∆°ng lai t·ª´ th·ªùi ƒëi·ªÉm x√°c ƒë·ªãnh"""
    
    # N·∫øu c√≥ ng√†y b·∫Øt ƒë·∫ßu ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh, s·ª≠ d·ª•ng n√≥
    if start_date is not None:
        # T·∫°o datetime t·ª´ ng√†y v√† gi·ªù ƒë∆∞·ª£c ch·ªçn
        start_datetime = datetime.combine(start_date, datetime.min.time())
        start_datetime = start_datetime.replace(hour=start_hour)
    else:
        # N·∫øu kh√¥ng, s·ª≠ d·ª•ng ng√†y cu·ªëi c√πng t·ª´ d·ªØ li·ªáu hi·ªán c√≥
        last_date = data['ds'].max()
        
        # T√¨m m·ªëc th·ªùi gian ti·∫øp theo (00, 06, 12, 18)
        current_hour = last_date.hour
        next_time_slot = (current_hour // 6 + 1) * 6
        if next_time_slot == 24:
            # Chuy·ªÉn sang ng√†y h√¥m sau ·ªü m√∫i gi·ªù 00
            start_datetime = (last_date + timedelta(days=1)).replace(hour=0, minute=0, second=0, microsecond=0)
        else:
            # Chuy·ªÉn sang m·ªëc gi·ªù ti·∫øp theo trong ng√†y
            start_datetime = last_date.replace(hour=next_time_slot, minute=0, second=0, microsecond=0)
    
    # T·∫°o c√°c m·ªëc th·ªùi gian cho s·ªë ng√†y c·∫ßn d·ª± b√°o
    future_dates = []
    for day in range(num_days):
        for hour in [0, 6, 12, 18]:
            # T√≠nh to√°n ng√†y v√† gi·ªù cho m·ªói ƒëi·ªÉm d·ª± b√°o
            forecast_date = start_datetime + timedelta(days=day)
            forecast_date = forecast_date.replace(hour=hour)
            future_dates.append(forecast_date)
    
    # Lo·∫°i b·ªè c√°c m·ªëc th·ªùi gian tr∆∞·ªõc th·ªùi ƒëi·ªÉm b·∫Øt ƒë·∫ßu
    future_dates = [date for date in future_dates if date >= start_datetime]
    
    # Ch·ªâ l·∫•y ƒë√∫ng s·ªë ƒëi·ªÉm c·∫ßn thi·∫øt (4 ƒëi·ªÉm/ng√†y * s·ªë ng√†y)
    future_dates = future_dates[:num_days * 4]
    
    # T·∫°o DataFrame cho d·ªØ li·ªáu t∆∞∆°ng lai
    future_df = pd.DataFrame({
        'unique_id': [unique_id] * len(future_dates),
        'ds': future_dates,
        'y': [np.nan] * len(future_dates)  # NaN v√¨ ch∆∞a c√≥ gi√° tr·ªã th·ª±c t·∫ø
    })
    
    return future_df

def detect_anomalies(actual, predicted, scaler, threshold_std=3):
    """Ph√°t hi·ªán b·∫•t th∆∞·ªùng d·ª±a tr√™n sai s·ªë gi·ªØa gi√° tr·ªã th·ª±c t·∫ø v√† d·ª± b√°o"""
    try:
        # Inverse transform ƒë·ªÉ c√≥ gi√° tr·ªã th·ª±c
        y_true = scaler.inverse_transform(actual[['y']])
        y_pred = scaler.inverse_transform(predicted[['NHITS']])
        
        # T√≠nh to√°n sai s·ªë
        error = np.abs(y_true - y_pred)
        
        # T√≠nh ng∆∞·ª°ng ph√°t hi·ªán b·∫•t th∆∞·ªùng
        err_mean = np.mean(error)
        err_std = np.std(error)
        threshold = err_mean + threshold_std * err_std
        
        # ƒê√°nh d·∫•u b·∫•t th∆∞·ªùng
        anomalies = error > threshold
        
        # T·∫°o DataFrame k·∫øt qu·∫£
        result = pd.DataFrame({
            'ds': actual['ds'].values,
            'y_true': y_true.flatten(),
            'y_pred': y_pred.flatten(),
            'error': error.flatten(),
            'anomaly': anomalies.flatten().astype(int)
        })
        
        return result, threshold
    except Exception as e:
        st.error(f"L·ªói khi ph√°t hi·ªán b·∫•t th∆∞·ªùng: {e}")
        return None, None

def create_forecast_plot(result_df, future_result=None, title="D·ª± b√°o s·∫£n l∆∞·ª£ng ƒëi·ªán"):
    """T·∫°o bi·ªÉu ƒë·ªì d·ª± b√°o vs th·ª±c t·∫ø s·ª≠ d·ª•ng Plotly"""
    try:
        fig = go.Figure()
        
        # Th√™m ƒë∆∞·ªùng d·ª± b√°o
        fig.add_trace(go.Scatter(
            x=result_df['ds'],
            y=result_df['y_pred'],
            mode='lines+markers',
            name='D·ª± b√°o (hi·ªán t·∫°i)',
            line=dict(color='rgba(65, 105, 225, 0.8)', width=2),
            marker=dict(symbol='circle', size=6)
        ))
        
        # Th√™m ƒë∆∞·ªùng th·ª±c t·∫ø
        fig.add_trace(go.Scatter(
            x=result_df['ds'],
            y=result_df['y_true'],
            mode='lines+markers',
            name='Th·ª±c t·∫ø',
            line=dict(color='rgba(50, 205, 50, 0.8)', width=2),
            marker=dict(symbol='circle', size=8)
        ))
        
        # N·∫øu c√≥ d·ª± b√°o t∆∞∆°ng lai, th√™m v√†o bi·ªÉu ƒë·ªì
        if future_result is not None:
            fig.add_trace(go.Scatter(
                x=future_result['ds'],
                y=future_result['y_pred'],
                mode='lines+markers',
                name='D·ª± b√°o t∆∞∆°ng lai',
                line=dict(color='rgba(255, 165, 0, 0.8)', width=2, dash='dot'),
                marker=dict(symbol='triangle-up', size=8)
            ))
        
        # N·∫øu c√≥ b·∫•t th∆∞·ªùng, th√™m ƒëi·ªÉm ƒë√°nh d·∫•u
        if 'anomaly' in result_df.columns and result_df['anomaly'].sum() > 0:
            anomalies = result_df[result_df['anomaly'] == 1]
            fig.add_trace(go.Scatter(
                x=anomalies['ds'],
                y=anomalies['y_true'],
                mode='markers',
                name='B·∫•t th∆∞·ªùng',
                marker=dict(
                    symbol='x',
                    size=12,
                    color='rgba(255, 0, 0, 0.9)',
                    line=dict(width=2, color='rgba(255, 0, 0, 0.9)')
                )
            ))
        
        # C·∫≠p nh·∫≠t layout
        fig.update_layout(
            title=title,
            xaxis_title='Th·ªùi gian',
            yaxis_title='S·∫£n l∆∞·ª£ng ƒëi·ªán (kWh)',
            legend=dict(
                orientation="h",
                yanchor="bottom",
                y=1.02,
                xanchor="right",
                x=1
            ),
            template='plotly_white',
            height=500,
            hovermode='x unified'
        )
        
        fig.update_traces(hovertemplate='%{y:.2f} kWh')
        
        return fig
    except Exception as e:
        st.error(f"L·ªói khi t·∫°o bi·ªÉu ƒë·ªì: {e}")
        return None

def create_error_plot(result_df, threshold, title="Sai s·ªë d·ª± b√°o"):
    """T·∫°o bi·ªÉu ƒë·ªì hi·ªÉn th·ªã sai s·ªë d·ª± b√°o v√† ng∆∞·ª°ng ph√°t hi·ªán b·∫•t th∆∞·ªùng"""
    try:
        fig = go.Figure()
        
        # Th√™m ƒë∆∞·ªùng sai s·ªë
        fig.add_trace(go.Scatter(
            x=result_df['ds'],
            y=result_df['error'],
            mode='lines+markers',
            name='Sai s·ªë',
            line=dict(color='rgba(255, 165, 0, 0.8)', width=2),
            marker=dict(symbol='circle', size=6)
        ))
        
        # Th√™m ƒë∆∞·ªùng ng∆∞·ª°ng
        fig.add_trace(go.Scatter(
            x=result_df['ds'],
            y=[threshold] * len(result_df),
            mode='lines',
            name='Ng∆∞·ª°ng ph√°t hi·ªán',
            line=dict(color='rgba(255, 0, 0, 0.6)', width=2, dash='dash')
        ))
        
        # N·∫øu c√≥ b·∫•t th∆∞·ªùng, ƒë√°nh d·∫•u
        if 'anomaly' in result_df.columns and result_df['anomaly'].sum() > 0:
            anomalies = result_df[result_df['anomaly'] == 1]
            fig.add_trace(go.Scatter(
                x=anomalies['ds'],
                y=anomalies['error'],
                mode='markers',
                name='B·∫•t th∆∞·ªùng',
                marker=dict(
                    symbol='x',
                    size=12,
                    color='rgba(255, 0, 0, 0.9)',
                    line=dict(width=2, color='rgba(255, 0, 0, 0.9)')
                )
            ))
        
        # C·∫≠p nh·∫≠t layout
        fig.update_layout(
            title=title,
            xaxis_title='Th·ªùi gian',
            yaxis_title='Sai s·ªë tuy·ªát ƒë·ªëi (kWh)',
            legend=dict(
                orientation="h",
                yanchor="bottom",
                y=1.02,
                xanchor="right",
                x=1
            ),
            template='plotly_white',
            height=400,
            hovermode='x unified'
        )
        
        fig.update_traces(hovertemplate='%{y:.2f} kWh')
        
        return fig
    except Exception as e:
        st.error(f"L·ªói khi t·∫°o bi·ªÉu ƒë·ªì sai s·ªë: {e}")
        return None

def calculate_metrics(result_df):
    """T√≠nh to√°n c√°c ch·ªâ s·ªë ƒë√°nh gi√°"""
    try:
        # MAE - Mean Absolute Error
        mae = np.mean(result_df['error'])
        
        # MAPE - Mean Absolute Percentage Error
        mape = np.mean(np.abs(result_df['y_true'] - result_df['y_pred']) / (result_df['y_true'] + 1e-8)) * 100
        
        # S·ªë ƒëi·ªÉm b·∫•t th∆∞·ªùng
        if 'anomaly' in result_df.columns:
            anomaly_count = result_df['anomaly'].sum()
            anomaly_percent = (anomaly_count / len(result_df)) * 100
        else:
            anomaly_count = 0
            anomaly_percent = 0
        
        return {
            'mae': mae,
            'mape': mape,
            'anomaly_count': anomaly_count,
            'anomaly_percent': anomaly_percent
        }
    except Exception as e:
        st.error(f"L·ªói khi t√≠nh to√°n ch·ªâ s·ªë: {e}")
        return None

# --------- MAIN APP ----------

def main():
    # Ti√™u ƒë·ªÅ ·ª©ng d·ª•ng
    st.title("‚ö° Electric Power Generation Forecasting and Operational Anomaly Detection")
    st.sidebar.image("image.png", width=300)
    st.sidebar.header("Input Parameters")
    
    model_path = st.sidebar.text_input("Model Path", value="./models/nhits_model/")
    scalers_path = st.sidebar.text_input("Path to Scaler Objects ", value="./models/scalers.pkl")
    data_path = st.sidebar.text_input("Path to Preprocessing Scalers", value="data/test.csv")
    
    # Ki·ªÉm tra c√°c ƒë∆∞·ªùng d·∫´n
    if not os.path.exists(model_path):
        st.sidebar.error(f"Model directory not found: {model_path}")
        st.stop()
    if not os.path.exists(scalers_path):
        st.sidebar.error(f"Scaler file not found: {scalers_path}")
        st.stop()
    if not os.path.exists(data_path):
        st.sidebar.error(f"Data file not found: {data_path}")  
        st.stop()
    
    # T·∫£i m√¥ h√¨nh, scalers v√† d·ªØ li·ªáu
    with st.sidebar:
        with st.spinner("Loading the model and dataset..."):
            model, scalers = load_model_and_scalers(model_path, scalers_path)
            df = load_data(data_path)
            unique_ids = get_unique_ids(df)
    
    selected_id = st.sidebar.selectbox("Select electricity meter (unique_id)", unique_ids)
    enable_future_forecast = st.sidebar.checkbox("Next day forecast", value=False)
    
    forecast_days = 7  
    if enable_future_forecast:
        forecast_days = st.sidebar.slider("Number of forecast days", 1, 30, 7)
        
        start_forecast_date = st.sidebar.date_input(
            "Select forecast start date",
            datetime.now().date()
        )
        
        start_forecast_hour = st.sidebar.selectbox(
            " Select forecast start time",
            [0, 6, 12, 18],
            index=0  
        )
    
    samples_per_day = 4
    forecast_len = forecast_days * samples_per_day
    anomaly_threshold = st.sidebar.slider(
        " Anomaly detection threshold (number of standard deviations)",
        1.0, 5.0, 3.0, 0.1
    )
    
    analyze_button = st.sidebar.button("Data analysis")
    
    if analyze_button:
        with st.sidebar:
            with st.spinner(f"Analyzing data for the meter {selected_id}..."):
                data = prepare_data_for_prediction(df, selected_id)
                
                if data is None or len(data) < 10:
                    st.error(f"Insufficient data for the meter {selected_id}")
                    st.stop()
                
                data_scaled, scaler = scale_data(data, scalers, selected_id)
                
                if data_scaled is None or scaler is None:
                    st.error(f"Unable to normalize data for the meter {selected_id}")
                    st.stop()
                
                validation_len = 28 
                train_data = data_scaled.iloc[:-validation_len]
                test_data = data_scaled.iloc[-validation_len:]
                
                validation_forecast = make_forecast(model, train_data, validation_len)
                
                if validation_forecast is None:
                    st.error("Unable to generate forecast")
                    st.stop()
                
                merged = pd.merge(test_data, validation_forecast, on=['ds', 'unique_id'], how='inner')
                result_df, threshold = detect_anomalies(merged, merged, scaler, threshold_std=anomaly_threshold)
                
                if result_df is None:
                    st.error("Unable to detect anomalies")
                    st.stop()
                
                future_result = None
                if enable_future_forecast:
                    future_df = prepare_future_data(
                                                    data, 
                                                    selected_id, 
                                                    forecast_days,
                                                    start_date=start_forecast_date,
                                                    start_hour=start_forecast_hour
                                                )
                    
                    future_forecast = make_forecast(model, data_scaled, len(future_df))
                    
                    if future_forecast is not None:
                        min_len = min(len(future_df), len(future_forecast))
                        future_result = pd.DataFrame({
                                            'ds': future_df['ds'].values[:min_len],
                                            'y_pred': scaler.inverse_transform(future_forecast[['NHITS']][:min_len]).flatten()
                                        })
                        print(f"Length of future_df: {len(future_df)}, Length of future_forecast: {len(future_forecast)}")

        metrics = calculate_metrics(result_df)

        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.markdown('<div class="metric-card">', unsafe_allow_html=True)
            st.markdown(f'<p class="metric-value">{metrics["mae"]:.2f}</p>', unsafe_allow_html=True)
            st.markdown('<p class="metric-label">MAE (kWh)</p>', unsafe_allow_html=True)
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col2:
            st.markdown('<div class="metric-card">', unsafe_allow_html=True)
            st.markdown(f'<p class="metric-value">{metrics["mape"]:.2f}%</p>', unsafe_allow_html=True)
            st.markdown('<p class="metric-label">MAPE</p>', unsafe_allow_html=True)
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col3:
            st.markdown('<div class="metric-card">', unsafe_allow_html=True)
            st.markdown(f'<p class="metric-value">{metrics["anomaly_count"]}</p>', unsafe_allow_html=True)
            st.markdown('<p class="metric-label">ƒêi·ªÉm b·∫•t th∆∞·ªùng</p>', unsafe_allow_html=True)
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col4:
            st.markdown('<div class="metric-card">', unsafe_allow_html=True)
            st.markdown(f'<p class="metric-value">{metrics["anomaly_percent"]:.1f}%</p>', unsafe_allow_html=True)
            st.markdown('<p class="metric-label">T·ª∑ l·ªá b·∫•t th∆∞·ªùng</p>', unsafe_allow_html=True)
            st.markdown('</div>', unsafe_allow_html=True)
        
        st.markdown("---")
        
        st.subheader(f"üìà  Forecast results for the meter {selected_id}")
        
        if enable_future_forecast:
            start_datetime_str = f"{start_forecast_date.strftime('%d/%m/%Y')} {start_forecast_hour:02d}:00"
            end_date = start_forecast_date + timedelta(days=forecast_days)
            end_datetime_str = f"{end_date.strftime('%d/%m/%Y')} {start_forecast_hour:02d}:00"
            st.info(f"Forecast from {start_datetime_str} to {end_datetime_str} ({forecast_len} data points) at hours: 00:00, 06:00, 12:00, 18:00")

        forecast_fig = create_forecast_plot(
            result_df, 
            future_result=future_result, 
            title=f"Electricity Production Forecast ‚Äì Meter {selected_id}"
        )
        if forecast_fig:
            st.plotly_chart(forecast_fig, use_container_width=True)
        
        error_fig = create_error_plot(result_df, threshold, title=f"Forecast Error ‚Äì Meter {selected_id}")
        if error_fig:
            st.plotly_chart(error_fig, use_container_width=True)
        
        if enable_future_forecast and future_result is not None:
            st.subheader(f"üîÆ Forecast for the next {forecast_days} days")
            
            future_display = future_result.copy()
            future_display['ds'] = future_display['ds'].dt.strftime('%d/%m/%Y %H:%M')
            future_display.rename(columns={
                'ds': 'Time',
                'y_pred': 'Forecast (kWh)'
            }, inplace=True)
            
            future_display['Forecast (kWh)'] = future_display['Forecast (kWh)'].round(2)
            
            st.dataframe(
                future_display,
                use_container_width=True,
                hide_index=True
            )
            
            csv_data = future_display.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="üì• Download file CSV forecast",
                data=csv_data,
                file_name=f"electricity_forecast_{forecast_days}_days_meter_{selected_id}.csv",
                mime="text/csv",
            )
        
        if metrics["anomaly_count"] > 0:
            st.subheader("üö®  Anomaly point details")
            anomalies = result_df[result_df['anomaly'] == 1].copy()
            anomalies['ds'] = anomalies['ds'].dt.strftime('%d/%m/%Y %H:%M')
            anomalies.rename(columns={
                    'ds': 'Time',
                    'y_true': 'Actual (kWh)',
                    'y_pred': 'Forecast (kWh)',
                    'error': 'Error (kWh)'
                }, inplace=True)
            
            anomalies_display = anomalies[['Time', 'Actual (kWh)', 'Forecast (kWh)', 'Error (kWh)']].copy()
            anomalies_display['Actual (kWh)'] = anomalies_display['Actual (kWh)'].round(2)
            anomalies_display['Forecast (kWh)'] = anomalies_display['Forecast (kWh)'].round(2)
            anomalies_display['Error (kWh)'] = anomalies_display['Error (kWh)'].round(2)
            
            st.dataframe(
                anomalies_display,
                use_container_width=True,
                hide_index=True
            )
            
            csv_data = anomalies_display.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="üì• Download Anomalies CSV",
                data=csv_data,
                file_name=f"anomalies_meter_{selected_id}.csv",
                mime="text/csv",
            )
        else:
            st.success("‚úÖ No anomalies detected with the current threshold.")

    st.sidebar.markdown("---")
    st.sidebar.info(
        """
        ‚ÑπÔ∏è **User Guide**  
        1. Select the meter to analyze  
        2. Enable ‚ÄúForecast for the next day‚Äù and choose the number of forecast days  
        3. Adjust the anomaly detection threshold  
        4. Click the ‚ÄúAnalyze Data‚Äù button  
        """
    )

if __name__ == "__main__":
    main()